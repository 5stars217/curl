{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight: torch.Size([28996, 768])\n",
      "bert.embeddings.position_embeddings.weight: torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight: torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight: torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.pooler.dense.weight: torch.Size([768, 768])\n",
      "bert.pooler.dense.bias: torch.Size([768])\n",
      "classifier.weight: torch.Size([2, 768])\n",
      "classifier.bias: torch.Size([2])\n",
      "n_weight=108208896, n_bias=102914, n_param=108311810\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "bert_model = BertForSequenceClassification.from_pretrained('gchhablani/bert-base-cased-finetuned-qnli')\n",
    "bert_model.eval()\n",
    "\n",
    "# Access the model's weights\n",
    "weights = bert_model.state_dict()\n",
    "\n",
    "# Modify the weights or perform any operation you desire\n",
    "# Example: Print the shape of each weight tensor\n",
    "o = 0\n",
    "b = 0\n",
    "for name, weight in weights.items():\n",
    "    if \"weight\" in str(name):\n",
    "        print(f\"{name}: {weight.size()}\")\n",
    "        p = 1\n",
    "        for w in weight.size():\n",
    "            p *= w\n",
    "        o += p\n",
    "    elif \"bias\" in str(name):\n",
    "        print(f\"{name}: {weight.size()}\")\n",
    "        p = 1\n",
    "        for w in weight.size():\n",
    "            p *= w\n",
    "        b += p\n",
    "    else:\n",
    "        print(f\"else {name}: {weight.size()}\")\n",
    "print(f\"n_weight={o}, n_bias={b}, n_param={o+b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.5781,  0.1473]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gchhablani/bert-base-cased-finetuned-qnli\")\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = bert_model(**inputs)\n",
    "realput = outputs\n",
    "print(realput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def load_tsv(data_file, max_seq_len, delimiter='\\t'):\n",
    "    '''Load a tsv '''\n",
    "    sentences = []\n",
    "    targets = []\n",
    "    with codecs.open(data_file, 'r', 'utf-8') as data_fh:\n",
    "        for _ in range(1):\n",
    "            data_fh.readline()\n",
    "        for row in data_fh:\n",
    "            row = row.strip().split(delimiter)\n",
    "            sentences.append(tokenizer(row[1], row[2], return_tensors=\"pt\"))\n",
    "            targets.append(1*(row[3] == \"not_entailment\"))\n",
    "    return sentences, targets\n",
    "\n",
    "data, targets = load_tsv(\"GLUE-baselines/glue_data/QNLI/dev.tsv\", 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for label in range(100):\n",
    "    outputs = bert_model(**data[label])\n",
    "    count += targets[label] == outputs.logits.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0, \"invalid heads and embedding dimension\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.search_dim = embed_dim // num_heads\n",
    "\n",
    "        self.key = torch.nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = torch.nn.Linear(embed_dim, embed_dim)\n",
    "        self.query = torch.nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj = torch.nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).permute(0, 2, 3, 1)\n",
    "        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "\n",
    "        attn = q.matmul(k_t) / math.sqrt(q.size(-1))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        y = attn.matmul(v)\n",
    "        y = y.transpose(1, 2)\n",
    "        y = y.reshape(batch_size, seq_len, self.embed_dim)\n",
    "        return y\n",
    "\n",
    "\n",
    "class BertBlock(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(BertBlock, self).__init__()\n",
    "        embed_dim = embed_dim\n",
    "        self.ln1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.attn = Attention(embed_dim, num_heads)\n",
    "        self.ff = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embed_dim, embed_dim * 4),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(embed_dim * 4, embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x + self.attn(x))\n",
    "        x = self.ln2(x + self.ff(x))\n",
    "        return x\n",
    "\n",
    "class Bert(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_blocks, vocab_size, seq_len, full=True):\n",
    "        super(Bert, self).__init__()\n",
    "        self.full = full\n",
    "        if full:\n",
    "            self.word_embed = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "            self.pos_embed = torch.nn.Parameter(torch.zeros(1, seq_len, embed_dim))\n",
    "            self.type_embed = torch.nn.Embedding(2, embed_dim)\n",
    "            self.ln = torch.nn.LayerNorm(embed_dim)\n",
    "        self.blocks = torch.nn.Sequential(\n",
    "            *[BertBlock(embed_dim, num_heads) for _ in range(num_blocks)]\n",
    "        )\n",
    "        if full:\n",
    "            self.pooler = torch.nn.Linear(embed_dim, embed_dim)\n",
    "            self.classifier = torch.nn.Linear(embed_dim, 2)\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        if self.full:\n",
    "            word_embedding = self.word_embed(x[\"input_ids\"])\n",
    "            pos_embedding = self.pos_embed[:, :x[\"input_ids\"].size()[1], :]\n",
    "            type_embedding = self.type_embed(x[\"token_type_ids\"])\n",
    "            x = word_embedding + pos_embedding + type_embedding\n",
    "            x = self.ln(x)\n",
    "        x = self.blocks(x)\n",
    "        if self.full:\n",
    "            x = self.pooler(x[:, 0, :])\n",
    "            x = x.tanh()\n",
    "            x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "plain_model = Bert(768, 12, 12, 30522, 1024, True) # bert base 13.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_model.word_embed.weight = torch.nn.Parameter(weights[\"bert.embeddings.word_embeddings.weight\"])\n",
    "plain_model.pos_embed.data = torch.nn.Parameter(weights[\"bert.embeddings.position_embeddings.weight\"][None, :, :])\n",
    "plain_model.type_embed.weight = torch.nn.Parameter(weights[\"bert.embeddings.token_type_embeddings.weight\"])\n",
    "plain_model.ln.weight = torch.nn.Parameter(weights[\"bert.embeddings.LayerNorm.weight\"])\n",
    "plain_model.ln.bias = torch.nn.Parameter(weights[\"bert.embeddings.LayerNorm.bias\"])\n",
    "for m in range(len(plain_model.blocks._modules)):\n",
    "    layer = \"bert.encoder.layer.\"\n",
    "    plain_model.blocks._modules[str(m)].attn.query.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.query.weight\"])\n",
    "    plain_model.blocks._modules[str(m)].attn.query.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.query.bias\"])\n",
    "    plain_model.blocks._modules[str(m)].attn.key.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.key.weight\"])\n",
    "    plain_model.blocks._modules[str(m)].attn.key.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.key.bias\"])\n",
    "    plain_model.blocks._modules[str(m)].attn.value.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.value.weight\"])\n",
    "    plain_model.blocks._modules[str(m)].attn.value.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.value.bias\"])\n",
    "    plain_model.blocks._modules[str(m)].attn.proj.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.dense.weight\"]) # .t()\n",
    "    plain_model.blocks._modules[str(m)].attn.proj.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.dense.bias\"])\n",
    "    plain_model.blocks._modules[str(m)].ln1.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.LayerNorm.weight\"])\n",
    "    plain_model.blocks._modules[str(m)].ln1.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.LayerNorm.bias\"])\n",
    "    plain_model.blocks._modules[str(m)].ff._modules['0'].weight = torch.nn.Parameter(weights[layer+str(m)+\".intermediate.dense.weight\"]) # .t()\n",
    "    plain_model.blocks._modules[str(m)].ff._modules['0'].bias = torch.nn.Parameter(weights[layer+str(m)+\".intermediate.dense.bias\"])\n",
    "    plain_model.blocks._modules[str(m)].ff._modules['2'].weight = torch.nn.Parameter(weights[layer+str(m)+\".output.dense.weight\"]) # .t()\n",
    "    plain_model.blocks._modules[str(m)].ff._modules['2'].bias = torch.nn.Parameter(weights[layer+str(m)+\".output.dense.bias\"])\n",
    "    plain_model.blocks._modules[str(m)].ln2.weight = torch.nn.Parameter(weights[layer+str(m)+\".output.LayerNorm.weight\"])\n",
    "    plain_model.blocks._modules[str(m)].ln2.bias = torch.nn.Parameter(weights[layer+str(m)+\".output.LayerNorm.bias\"])\n",
    "plain_model.pooler.weight = torch.nn.Parameter(weights[\"bert.pooler.dense.weight\"]) # .t()\n",
    "plain_model.pooler.bias = torch.nn.Parameter(weights[\"bert.pooler.dense.bias\"])\n",
    "plain_model.classifier.weight = torch.nn.Parameter(weights[\"classifier.weight\"]) # .t()\n",
    "plain_model.classifier.bias = torch.nn.Parameter(weights[\"classifier.bias\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output\n",
      "output.shape=torch.Size([1, 2])\n",
      "output=tensor([[-0.7974,  0.5348]], grad_fn=<AddmmBackward0>)\n",
      "0.5348405241966248 -0.7973539233207703\n",
      "-0.13125669956207275 0.8873710036277771\n"
     ]
    }
   ],
   "source": [
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# Classify the encrypted data\n",
    "print(\"forward\")\n",
    "x = {}\n",
    "x['input_ids'] = data[0][\"input_ids\"]\n",
    "x['token_type_ids'] = data[0][\"token_type_ids\"]\n",
    "# x['input_ids'] = torch.tensor([1])\n",
    "# x['token_type_ids'] = torch.tensor([0, 1, 0, 1])\n",
    "word_embedding = plain_model.word_embed(x[\"input_ids\"])\n",
    "pos_embedding = plain_model.pos_embed[:, :x[\"input_ids\"].size()[1], :]\n",
    "type_embedding = plain_model.type_embed(x[\"token_type_ids\"])\n",
    "x = word_embedding + pos_embedding + type_embedding\n",
    "x = plain_model.ln(x)\n",
    "# v = '0'\n",
    "# x = plain_model.blocks._modules[v].attn(x)\n",
    "x = plain_model.blocks._modules['0'](x)\n",
    "x = plain_model.blocks._modules['1'](x)\n",
    "x = plain_model.blocks._modules['2'](x)\n",
    "x = plain_model.blocks._modules['3'](x)\n",
    "x = plain_model.blocks._modules['4'](x)\n",
    "x = plain_model.blocks._modules['5'](x)\n",
    "x = plain_model.blocks._modules['6'](x)\n",
    "x = plain_model.blocks._modules['7'](x)\n",
    "x = plain_model.blocks._modules['8'](x)\n",
    "x = plain_model.blocks._modules['9'](x)\n",
    "x = plain_model.blocks._modules['10'](x)\n",
    "x = plain_model.blocks._modules['11'](x)\n",
    "x = plain_model.pooler(x[:, 0, :])\n",
    "x = x.tanh()\n",
    "x = plain_model.classifier(x)\n",
    "\n",
    "# x = plain_model(x)\n",
    "print('output')\n",
    "# Compute the accuracy\n",
    "output = x\n",
    "print(f\"{output.shape=}\")\n",
    "print(f\"{output=}\")\n",
    "print(f\"{output.max()} {output.min()}\")\n",
    "print(f\"{output.mean()} {output.var()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7974,  0.5348]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6113,  0.3770]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6552,  0.3993]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2674,  0.0475]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0812,  0.0456]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1108,  0.0706]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.5361,  0.2477]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.0271,  0.7352]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0689, -0.0279]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.5986,  0.4556]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for label in range(10):\n",
    "    x = {}\n",
    "    x['input_ids'] = data[label][\"input_ids\"]\n",
    "    x['token_type_ids'] = data[label][\"token_type_ids\"]\n",
    "    outputs = plain_model(x)\n",
    "    print(outputs)\n",
    "    count += targets[label] == outputs.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0014, -1.6264]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5682,  2.9418]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8672,  2.4340]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 3.1729, -2.6355]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.2055,  1.8402]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6816,  3.0014]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.3215,  1.2353]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.7192,  2.9996]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.8530,  3.0773]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 3.5189, -2.9471]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    outputs = bert_model(**data[i])\n",
    "    print(outputs.logits)\n",
    "    count += targets[i] == outputs.logits.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "390894444956881"
  },
  "disseminate_notebook_info": {
   "bento_version": "20190826-030256",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "error": "The file located at '/data/users/shobha/fbsource/fbcode/bento/kernels/local/cryptenk/TARGETS' could not be found."
   },
   "no_uii": true,
   "notebook_number": "139932",
   "others_can_edit": true,
   "reviewers": "",
   "revision_id": "375902760006757",
   "tags": "",
   "tasks": "",
   "title": "Tutorial 4 -- Classification with Encrypted Neural Networks"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
