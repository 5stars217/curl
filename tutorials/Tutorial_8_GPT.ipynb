{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification with Encrypted Neural Networks\n",
    "\n",
    "In this tutorial, we'll look at how we can achieve the <i>Model Hiding</i> application we discussed in the Introduction. That is, suppose say Alice has a trained model she wishes to keep private, and Bob has some data he wishes to classify while keeping it private. We will see how CrypTen allows Alice and Bob to coordinate and classify the data, while achieving their privacy requirements.\n",
    "\n",
    "To simulate this scenario, we will begin with Alice training a simple neural network on MNIST data. Then we'll see how Alice and Bob encrypt their network and data respectively, classify the encrypted data and finally decrypt the labels.\n",
    "\n",
    "## Setup\n",
    "\n",
    "We first import the `torch` and `crypten` libraries, and initialize `crypten`. We will use a helper script `mnist_utils.py` to split the public MNIST data into Alice's portion and Bob's portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ProcessGroupGloo.cpp:751] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n"
     ]
    }
   ],
   "source": [
    "import curl\n",
    "import curl.nn as nn\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6223,  0.6879,  0.0748, -1.2729, -1.3618,  0.3635, -1.4101,\n",
       "          -1.3043]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0, \"invalid heads and embedding dimension\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.search_dim = embed_dim // num_heads\n",
    "\n",
    "        self.search = torch.nn.Linear(embed_dim, 3 * embed_dim)\n",
    "        self.proj = torch.nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        query, key, value = self.search(x).split(self.embed_dim, dim=2)\n",
    "        query = query.reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "        key = key.reshape(batch_size, seq_len, self.num_heads, self.search_dim).permute(0, 2, 3, 1)\n",
    "        value = value.reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "\n",
    "        attn = query.matmul(key) / math.sqrt(query.size(-1))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        y = attn.matmul(value).transpose(1, 2).reshape(batch_size, seq_len, self.embed_dim)\n",
    "        y = self.proj(y)\n",
    "        return y\n",
    "\n",
    "layer = Attention(8, 2)\n",
    "sw = layer.search.weight\n",
    "sb = layer.search.bias\n",
    "pw = layer.proj.weight\n",
    "pb = layer.proj.bias\n",
    "data = torch.tensor([1, 2, 0, 1, 2, 3, 4, 2], dtype=torch.float).reshape(1, 1, 8)\n",
    "layer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6223,  0.6878,  0.0748, -1.2728, -1.3617,  0.3634, -1.4100,\n",
       "          -1.3042]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Attention(8, 2)\n",
    "layer.search.weight = sw\n",
    "layer.search.bias = sb\n",
    "layer.proj.weight = pw\n",
    "layer.proj.bias = pb\n",
    "layer.encrypt(src=0)\n",
    "data = torch.tensor([1, 2, 0, 1, 2, 3, 4, 2], dtype=torch.float).reshape(1, 1, 8)\n",
    "data_enc = crypten.cryptensor(data)\n",
    "output = layer.forward(data_enc)\n",
    "output.get_plain_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.3749, -1.7004, -0.7123, -0.6363, -0.0685, -0.0942, -0.5310,  3.0206,\n",
      "         -0.3940, -1.6077],\n",
      "        [ 0.8402, -1.5226, -0.7774, -0.9728,  0.2623,  1.9485, -1.1585,  1.8922,\n",
      "          0.7155,  0.1293],\n",
      "        [ 0.7431,  1.7675,  0.0258,  0.6285,  1.3089,  0.3253, -2.4253,  0.3428,\n",
      "         -1.0613,  1.7637],\n",
      "        [-0.1879, -0.9199,  1.0139,  2.8269,  1.6581, -1.7827,  0.8733,  1.2514,\n",
      "         -1.3100, -2.0500],\n",
      "        [-0.3762, -1.0989,  1.9507, -0.7418,  0.3374, -0.7515,  0.3272, -0.1313,\n",
      "         -0.8547,  1.1360]], requires_grad=True)\n",
      "tensor([[ 0.8402, -1.5226, -0.7774, -0.9728,  0.2623,  1.9484, -1.1585,  1.8922,\n",
      "          0.7155,  0.1293],\n",
      "        [ 0.7430,  1.7675,  0.0258,  0.6285,  1.3089,  0.3253, -2.4253,  0.3428,\n",
      "         -1.0613,  1.7637],\n",
      "        [-1.3748, -1.7004, -0.7123, -0.6362, -0.0685, -0.0942, -0.5310,  3.0206,\n",
      "         -0.3940, -1.6077],\n",
      "        [ 0.8402, -1.5226, -0.7774, -0.9728,  0.2623,  1.9484, -1.1585,  1.8922,\n",
      "          0.7155,  0.1293],\n",
      "        [ 0.7430,  1.7675,  0.0258,  0.6285,  1.3089,  0.3253, -2.4253,  0.3428,\n",
      "         -1.0613,  1.7637],\n",
      "        [-0.1879, -0.9199,  1.0139,  2.8269,  1.6581, -1.7827,  0.8733,  1.2514,\n",
      "         -1.3100, -2.0500],\n",
      "        [-0.3762, -1.0989,  1.9507, -0.7418,  0.3374, -0.7515,  0.3272, -0.1313,\n",
      "         -0.8547,  1.1360]])\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Embedding(5, 10)\n",
    "print(layer.weight)\n",
    "layer.encrypt(src=0)\n",
    "data = torch.tensor([1, 2, 0, 1, 2, 3, 4])\n",
    "data_enc = crypten.cryptensor(data)\n",
    "output = layer.forward(data_enc)\n",
    "print(output.get_plain_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8402, -1.5226, -0.7774, -0.9728,  0.2623,  1.9484, -1.1585,  1.8922,\n",
       "          0.7155,  0.1293],\n",
       "        [ 0.7430,  1.7675,  0.0258,  0.6285,  1.3089,  0.3253, -2.4253,  0.3428,\n",
       "         -1.0613,  1.7637],\n",
       "        [-1.3748, -1.7004, -0.7123, -0.6362, -0.0685, -0.0942, -0.5310,  3.0206,\n",
       "         -0.3940, -1.6077],\n",
       "        [ 0.8402, -1.5226, -0.7774, -0.9728,  0.2623,  1.9484, -1.1585,  1.8922,\n",
       "          0.7155,  0.1293],\n",
       "        [ 0.7430,  1.7675,  0.0258,  0.6285,  1.3089,  0.3253, -2.4253,  0.3428,\n",
       "         -1.0613,  1.7637],\n",
       "        [-0.1879, -0.9199,  1.0139,  2.8269,  1.6581, -1.7827,  0.8733,  1.2514,\n",
       "         -1.3100, -2.0500],\n",
       "        [-0.3762, -1.0989,  1.9507, -0.7418,  0.3374, -0.7515,  0.3272, -0.1313,\n",
       "         -0.8547,  1.1360]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.nn.Embedding(5, 10)\n",
    "l.weight = torch.nn.Parameter(layer.weight.get_plain_text())\n",
    "l(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 0., 1., 2., 3., 4.])\n",
      "<built-in method type of Tensor object at 0x38764ba70>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11., 21., 31.],\n",
       "        [12., 22., 32.],\n",
       "        [10., 20., 30.],\n",
       "        [11., 21., 31.],\n",
       "        [12., 22., 32.],\n",
       "        [13., 23., 33.],\n",
       "        [14., 24., 34.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enc = crypten.cryptensor(torch.tensor([1, 2, 0, 1, 2, 3, 4])) #, dtype=torch.long))\n",
    "print(data_enc.get_plain_text())\n",
    "lut = crypten.cryptensor(torch.tensor([[10, 20, 30], [11, 21, 31], [12, 22, 32], [13, 23, 33], [14, 24, 34]])).share\n",
    "# print(lut / 2**16)\n",
    "data_enc.evaluate_embed(lut).get_plain_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:==================\n",
      "INFO:root:In LayerNorm\n",
      "INFO:root:==================\n",
      "INFO:root:weight=Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "INFO:root:bias=Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "INFO:root:==================\n",
      "INFO:root:In AUTOGRAD\n",
      "INFO:root:==================\n",
      "INFO:root:inv_var.get_plain_text()=tensor([[3.8304, 3.5486, 4.0272],\n",
      "        [3.0654, 2.5956, 2.2561]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output_enc\n",
      "output=tensor([[[ 1.2089,  4.1880,  2.9328, -1.1218],\n",
      "         [ 2.0143,  3.1603, -0.5563,  2.3644],\n",
      "         [ 1.4534,  1.7210,  5.9170, -1.1451]],\n",
      "\n",
      "        [[-0.0346,  3.8206,  5.3922,  1.3083],\n",
      "         [ 1.3207, -0.6203,  2.7214,  8.3293],\n",
      "         [ 0.7060,  4.9697,  1.1984,  1.6388]]])\n"
     ]
    }
   ],
   "source": [
    "model = nn.LayerNorm(4)\n",
    "model.weight = torch.tensor([1, 2, 3, 4])\n",
    "model.bias = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "data_enc = crypten.cryptensor(torch.rand(2, 3, 4)) #, dtype=torch.long))\n",
    "\n",
    "# print(f\"{data_enc.get_plain_text()=}\")\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.2462,  4.5780,  2.9208, -2.0350],\n",
      "         [ 2.1834,  3.3537, -1.1494,  2.0914],\n",
      "         [ 1.5395,  1.6681,  6.4706, -2.1216]],\n",
      "\n",
      "        [[-0.1971,  4.1063,  5.7676,  0.8856],\n",
      "         [ 1.3703, -1.0258,  2.6783,  8.9994],\n",
      "         [ 0.6606,  5.4288,  0.9198,  1.2737]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[0.5748, 0.5381, 0.7149],\n",
      "        [0.4933, 0.5724, 0.3004]])\n",
      "tensor([[0.0654, 0.0778, 0.0581],\n",
      "        [0.1060, 0.1484, 0.1965]])\n",
      "tensor([[3.9090, 3.5858, 4.1501],\n",
      "        [3.0716, 2.5958, 2.2559]])\n"
     ]
    }
   ],
   "source": [
    "layer = torch.nn.LayerNorm(4)\n",
    "layer.weight = torch.nn.Parameter(torch.tensor([1.0, 2.0, 3.0, 4.0]))\n",
    "layer.bias = torch.nn.Parameter(torch.tensor([1.0, 2.0, 3.0, 4.0]))\n",
    "print(layer(data_enc.get_plain_text()))\n",
    "print(data_enc.get_plain_text().mean(dim=-1))\n",
    "print(data_enc.get_plain_text().var(dim=-1))\n",
    "print(1/data_enc.get_plain_text().var(dim=-1).sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:==================\n",
      "INFO:root:In forward\n",
      "INFO:root:==================\n",
      "INFO:root:len(z)=3 z[0].size()=torch.Size([1, 128, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_enc\n",
      "output=tensor([[[-0.0951,  0.5813, -0.2107,  ..., -0.4085, -0.5018,  0.0266],\n",
      "         [-0.0892,  0.5837, -0.2138,  ..., -0.4075, -0.4968,  0.0253],\n",
      "         [-0.0956,  0.5900, -0.2074,  ..., -0.4109, -0.4960,  0.0366],\n",
      "         ...,\n",
      "         [-0.0831,  0.5868, -0.2061,  ..., -0.4033, -0.4971,  0.0261],\n",
      "         [-0.0977,  0.5806, -0.2147,  ..., -0.4079, -0.4925,  0.0246],\n",
      "         [-0.0893,  0.5836, -0.2094,  ..., -0.4067, -0.4975,  0.0306]]])\n"
     ]
    }
   ],
   "source": [
    "model = nn.Attention(768, 12)\n",
    "\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "data_enc = crypten.cryptensor(torch.rand(1, 128, 768)) #, dtype=torch.long))\n",
    "\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(Block, self).__init__()\n",
    "        embed_dim = embed_dim\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.Attention(embed_dim, num_heads, False)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# model = Block(768, 12)\n",
    "# model.encrypt(src=0)\n",
    "\n",
    "# # Load data to Bob\n",
    "# print('loading data')\n",
    "# # data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "# data_enc = crypten.cryptensor(torch.rand(1, 128, 768)) #, dtype=torch.long))\n",
    "\n",
    "# # Classify the encrypted data\n",
    "# model.eval()\n",
    "# print(\"forward\")\n",
    "# output_enc = model(data_enc)\n",
    "# print('output_enc')\n",
    "# # Compute the accuracy\n",
    "# output = output_enc.get_plain_text()\n",
    "# print(f\"{output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_blocks, vocab_size, seq_len, full=True):\n",
    "        super(GPT, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.full = full\n",
    "        if full:\n",
    "            self.tok_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.pos_embed = crypten.cryptensor(torch.zeros(1, seq_len, embed_dim))\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(embed_dim, num_heads) for _ in range(num_blocks)]\n",
    "        )\n",
    "        if full:\n",
    "            self.ln = nn.LayerNorm(embed_dim)\n",
    "            self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "            self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        if self.full:\n",
    "            tok_embedding = self.tok_embed(x)\n",
    "            pos_embedding = self.pos_embed[:, :x.size()[1], :]\n",
    "            x = tok_embedding + pos_embedding\n",
    "        x = self.blocks(x)\n",
    "        if self.full:\n",
    "            x = self.ln(x)\n",
    "            # x = self.fc(x)\n",
    "            # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# full = False\n",
    "# model = GPT(768, 12, 12, 50257, 128, full) # gpt2 13.5s\n",
    "# # model = GPT(2048, 16, 24, 50257, 128, full) # gpt-neo 2m 43.6s\n",
    "# # model = GPT(2560, 20, 32, 50257, 128, full) # gpt-neo-large 7m 9.7s\n",
    "# model.encrypt(src=0)\n",
    "\n",
    "# # Load data to Bob\n",
    "# print('loading data')\n",
    "# # data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "# if full:\n",
    "#     data_enc = crypten.cryptensor(torch.arange(model.seq_len).reshape(1, model.seq_len))\n",
    "# else:\n",
    "#     data_enc = crypten.cryptensor(torch.arange(model.seq_len * model.embed_dim).reshape(1, model.seq_len, model.embed_dim))\n",
    "\n",
    "# # Classify the encrypted data\n",
    "# model.eval()\n",
    "# print(\"forward\")\n",
    "# output_enc = model(data_enc)\n",
    "# print('output_enc')\n",
    "# # Compute the accuracy\n",
    "# output = output_enc.get_plain_text()\n",
    "# print(f\"{output=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2Model\n",
    "\n",
    "gpt2_model = GPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "# Access the model's weights\n",
    "gpt2_weights = gpt2_model.state_dict()\n",
    "\n",
    "# Modify the weights or perform any operation you desire\n",
    "# Example: Print the shape of each weight tensor\n",
    "# o = 0\n",
    "# b = 0\n",
    "# for name, weight in gpt2_weights.items():\n",
    "#     if \"weight\" in str(name):\n",
    "#         print(f\"{name}: {weight.size()}\")\n",
    "#         p = 1\n",
    "#         for w in weight.size():\n",
    "#             p *= w\n",
    "#         o += p\n",
    "#     elif \"bias\" in str(name):\n",
    "#         print(f\"{name}: {weight.size()}\")\n",
    "#         p = 1\n",
    "#         for w in weight.size():\n",
    "#             p *= w\n",
    "#         b += p\n",
    "#     else:\n",
    "#         print(f\"else {name}: {weight.size()}\")\n",
    "# print(f\"n_weight={o}, n_bias={b}, n_param={o+b}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = gpt2_model(**inputs)\n",
    "realput = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(768, 12, 12, 50257, 1024, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tok_embed.weight = gpt2_weights[\"wte.weight\"]\n",
    "model.pos_embed = crypten.cryptensor(gpt2_weights[\"wpe.weight\"][None, :, :])\n",
    "for m in range(len(model.blocks._modules)):\n",
    "    model.blocks._modules[str(m)].ln1.weight = gpt2_weights[\"h.\"+str(m)+\".ln_1.weight\"]\n",
    "    model.blocks._modules[str(m)].ln1.bias = gpt2_weights[\"h.\"+str(m)+\".ln_1.bias\"]\n",
    "    model.blocks._modules[str(m)].ln2.weight = gpt2_weights[\"h.\"+str(m)+\".ln_2.weight\"]\n",
    "    model.blocks._modules[str(m)].ln2.bias = gpt2_weights[\"h.\"+str(m)+\".ln_2.bias\"]\n",
    "    model.blocks._modules[str(m)].attn.search.weight = gpt2_weights[\"h.\"+str(m)+\".attn.c_attn.weight\"].t()\n",
    "    model.blocks._modules[str(m)].attn.search.bias = gpt2_weights[\"h.\"+str(m)+\".attn.c_attn.bias\"]\n",
    "    model.blocks._modules[str(m)].attn.proj.weight = gpt2_weights[\"h.\"+str(m)+\".attn.c_proj.weight\"].t()\n",
    "    model.blocks._modules[str(m)].attn.proj.bias = gpt2_weights[\"h.\"+str(m)+\".attn.c_proj.bias\"]\n",
    "    model.blocks._modules[str(m)].ff._modules['0'].weight = gpt2_weights[\"h.\"+str(m)+\".mlp.c_fc.weight\"].t()\n",
    "    model.blocks._modules[str(m)].ff._modules['0'].bias = gpt2_weights[\"h.\"+str(m)+\".mlp.c_fc.bias\"]\n",
    "    model.blocks._modules[str(m)].ff._modules['2'].weight = gpt2_weights[\"h.\"+str(m)+\".mlp.c_proj.weight\"].t()\n",
    "    model.blocks._modules[str(m)].ff._modules['2'].bias = gpt2_weights[\"h.\"+str(m)+\".mlp.c_proj.bias\"]\n",
    "model.ln.weight = gpt2_weights[\"ln_f.weight\"]\n",
    "model.ln.bias = gpt2_weights[\"ln_f.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output_enc\n",
      "output.shape=torch.Size([1, 6, 768])\n",
      "output=tensor([[[ 1.4915, -0.2492, -1.8059,  ...,  0.2848, -0.3922,  0.2562],\n",
      "         [ 0.5719, -0.8474, -0.8956,  ..., -0.9078,  0.5432,  0.5655],\n",
      "         [ 2.4399, -1.4238, -0.3864,  ..., -0.8836,  0.9537,  0.3114],\n",
      "         [ 0.2547, -0.6115, -1.2542,  ..., -1.3034,  0.5073,  0.1850],\n",
      "         [-1.0828, -0.1613, -1.5173,  ..., -0.4669,  0.0720, -0.0488],\n",
      "         [-0.5347, -1.2389, -1.0824,  ..., -0.0683,  0.5031,  0.6941]]])\n",
      "1371.1864013671875 -27.463058471679688\n",
      "0.2421594262123108 429.1286926269531\n"
     ]
    }
   ],
   "source": [
    "model.encrypt(src=0)\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "x = crypten.cryptensor(inputs[\"input_ids\"])\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "tok_embedding = model.tok_embed(x)\n",
    "pos_embedding = model.pos_embed[:, :x.size()[1], :]\n",
    "x = tok_embedding + pos_embedding\n",
    "x = model.blocks._modules['0'](x)\n",
    "x = model.blocks._modules['1'](x)\n",
    "x = model.blocks._modules['2'](x)\n",
    "v = '2'\n",
    "# y = model.blocks._modules[v].ln1(x)\n",
    "# x = x + model.blocks._modules[v].attn(y)\n",
    "# y = model.blocks._modules[v].ln2(x)\n",
    "# y = model.blocks._modules[v].ff._modules['0'](y)\n",
    "# y = model.blocks._modules[v].ff._modules['1'](y)\n",
    "# x = x + model.blocks._modules[v].ff._modules['2'](y)\n",
    "# print(f\"{x.mean().get_plain_text()}\")\n",
    "# print(f\"{x.var().inv_sqrt().get_plain_text()}\")\n",
    "# x = y\n",
    "# x = model.blocks._modules['3'](x)\n",
    "# x = model.blocks._modules['4'](x)\n",
    "# x = model.blocks._modules['5'](x)\n",
    "# x = model.blocks._modules['6'](x)\n",
    "# x = model.blocks._modules['7'](x)\n",
    "# x = model.blocks._modules['8'](x)\n",
    "# x = model.blocks._modules['9'](x)\n",
    "# x = model.blocks._modules['10'](x)\n",
    "# x = model.blocks._modules['11'](x)\n",
    "# x = model.ln(x)\n",
    "\n",
    "# x = model(x)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = x.get_plain_text()\n",
    "print(f\"{output.shape=}\")\n",
    "print(f\"{output=}\")\n",
    "print(f\"{output.max()} {output.min()}\")\n",
    "print(f\"{output.mean()} {output.var()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# model = Bert(128, 2, 2, 30522, 128, full) # bert tiny 0.3s\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# model = Bert(768, 12, 12, 30522, 128, full) # bert base 13.5s\u001b[39;00m\n\u001b[1;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m Bert(\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m30522\u001b[39m, \u001b[38;5;241m128\u001b[39m, full) \u001b[38;5;66;03m# bert large 44.8s\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Load data to Bob\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:504\u001b[0m, in \u001b[0;36mModule.encrypt\u001b[0;34m(self, mode, src)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers[name]\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;66;03m# apply encryption recursively:\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:467\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a function recursively on all modules.\"\"\"\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 467\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:467\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a function recursively on all modules.\"\"\"\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 467\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 467 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:467\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a function recursively on all modules.\"\"\"\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 467\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:468\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    467\u001b[0m     module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m--> 468\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:504\u001b[0m, in \u001b[0;36mModule.encrypt.<locals>.<lambda>\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers[name]\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;66;03m# apply encryption recursively:\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m m: \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:482\u001b[0m, in \u001b[0;36mModule.encrypt\u001b[0;34m(self, mode, src)\u001b[0m\n\u001b[1;32m    478\u001b[0m requires_grad \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mrequires_grad\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode:  \u001b[38;5;66;03m# encrypt parameter\u001b[39;00m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_parameter(\n\u001b[1;32m    481\u001b[0m         name,\n\u001b[0;32m--> 482\u001b[0m         \u001b[43mcrypten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcryptensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    485\u001b[0m     )\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# decrypt parameter\u001b[39;00m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_parameter(name, param\u001b[38;5;241m.\u001b[39mget_plain_text())\n",
      "File \u001b[0;32m~/Documents/curl/crypten/__init__.py:160\u001b[0m, in \u001b[0;36mcryptensor\u001b[0;34m(cryptensor_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrypTensor type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m cryptensor_type)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# create CrypTensor:\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCrypTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__CRYPTENSOR_TYPES__\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcryptensor_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/mpc/mpc.py:60\u001b[0m, in \u001b[0;36mMPCTensor.__init__\u001b[0;34m(self, tensor, ptype, device, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptype \u001b[38;5;241m=\u001b[39m ptype\n",
      "File \u001b[0;32m~/Documents/curl/crypten/mpc/primitives/arithmetic.py:102\u001b[0m, in \u001b[0;36mArithmeticSharedTensor.__init__\u001b[0;34m(self, tensor, size, broadcast_size, precision, src, device)\u001b[0m\n\u001b[1;32m     99\u001b[0m     size \u001b[38;5;241m=\u001b[39m comm\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mbroadcast_obj(size, src)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# generate pseudo-random zero sharing (PRZS) and add source's tensor:\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare \u001b[38;5;241m=\u001b[39m \u001b[43mArithmeticSharedTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRZS\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshare\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m src:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/Documents/curl/crypten/mpc/primitives/arithmetic.py:175\u001b[0m, in \u001b[0;36mArithmeticSharedTensor.PRZS\u001b[0;34m(device, *size)\u001b[0m\n\u001b[1;32m    173\u001b[0m g0 \u001b[38;5;241m=\u001b[39m generators[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev\u001b[39m\u001b[38;5;124m\"\u001b[39m][device]\n\u001b[1;32m    174\u001b[0m g1 \u001b[38;5;241m=\u001b[39m generators[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m][device]\n\u001b[0;32m--> 175\u001b[0m current_share \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_random_ring_element\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m next_share \u001b[38;5;241m=\u001b[39m generate_random_ring_element(\u001b[38;5;241m*\u001b[39msize, generator\u001b[38;5;241m=\u001b[39mg1, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    177\u001b[0m tensor\u001b[38;5;241m.\u001b[39mshare \u001b[38;5;241m=\u001b[39m current_share \u001b[38;5;241m-\u001b[39m next_share\n",
      "File \u001b[0;32m~/Documents/curl/crypten/common/rng.py:20\u001b[0m, in \u001b[0;36mgenerate_random_ring_element\u001b[0;34m(size, ring_size, generator, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     generator \u001b[38;5;241m=\u001b[39m crypten\u001b[38;5;241m.\u001b[39mgenerators[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m][device]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# TODO (brianknott): Check whether this RNG contains the full range we want.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m rand_element \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mring_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mring_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rand_element\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CUDALongTensor(rand_element)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class BertBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(BertBlock, self).__init__()\n",
    "        embed_dim = embed_dim\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.Attention(embed_dim, num_heads)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x + self.attn(x))\n",
    "        x = self.ln2(x + self.ff(x))\n",
    "        return x\n",
    "\n",
    "class Bert(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_blocks, vocab_size, seq_len, full=True):\n",
    "        super(Bert, self).__init__()\n",
    "        self.full = full\n",
    "        if full:\n",
    "            self.tok_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.pos_embed = crypten.cryptensor(torch.zeros(1, seq_len, embed_dim))\n",
    "        self.ln = nn.LayerNorm\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[BertBlock(embed_dim, num_heads) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        if full:\n",
    "            self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "            self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        if self.full:\n",
    "            tok_embedding = self.tok_embed(x)\n",
    "            pos_embedding = self.pos_embed[:, :x.size()[1], :]\n",
    "            x = tok_embedding + pos_embedding\n",
    "        x = self.ln(x)\n",
    "        x = self.blocks(x)\n",
    "        if self.full:\n",
    "            x = self.fc(x)\n",
    "            x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "full = False\n",
    "# model = Bert(128, 2, 2, 30522, 128, full) # bert tiny 0.3s\n",
    "# model = Bert(768, 12, 12, 30522, 128, full) # bert base 13.5s\n",
    "model = Bert(1024, 16, 24, 30522, 128, full) # bert large 44.8s\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "if full:\n",
    "    data_enc = crypten.cryptensor(torch.arange(64).reshape(1, 64))\n",
    "else:\n",
    "    data_enc = crypten.cryptensor(torch.arange(64 * 1024).reshape(1, 64, 1024))\n",
    "\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m         logging\u001b[38;5;241m.\u001b[39mgetLogger()\u001b[38;5;241m.\u001b[39msetLevel(level)\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[0;32m---> 57\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m model\u001b[38;5;241m.\u001b[39mencrypt(src\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Load data to Bob\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mAttention.__init__\u001b[0;34m(self, embed_dim, num_heads)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m embed_dim \u001b[38;5;241m%\u001b[39m num_heads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid heads and embedding dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim \u001b[38;5;241m=\u001b[39m embed_dim\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mnum_heads\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_dim \u001b[38;5;241m=\u001b[39m embed_dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_heads\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(embed_dim, embed_dim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0, \"invalid heads and embedding dimension\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = config.num_heads\n",
    "        self.search_dim = embed_dim // num_heads\n",
    "\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        level = logging.getLogger().level\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "        logging.info(\"==================\")\n",
    "        logging.info(\"In forward\" )\n",
    "        logging.info(\"==================\")\n",
    "# logging.getLogger().setLevel(level)\n",
    "\n",
    "        k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).permute(0, 2, 3, 1)\n",
    "        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "\n",
    "        logging.info(f\"{q.shape=}\")\n",
    "\n",
    "        attn = q.matmul(k_t) / math.sqrt(q.size(-1))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        logging.info(f\"{attn.shape=}\")\n",
    "        logging.info(f\"{v.shape=}\")\n",
    "\n",
    "        y = attn.matmul(v)\n",
    "\n",
    "        logging.info(f\"{y.shape=}\")\n",
    "\n",
    "        y = y.transpose(1, 2)\n",
    "\n",
    "        logging.info(f\"{y.shape=}\")\n",
    "\n",
    "        y = y.reshape(batch_size, seq_len, self.embed_dim)\n",
    "\n",
    "        logging.info(f\"{y.shape=}\")\n",
    "\n",
    "        logging.getLogger().setLevel(level)\n",
    "\n",
    "        return y\n",
    "\n",
    "model = Attention(768, 12)\n",
    "\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "data_enc = crypten.cryptensor(torch.rand(1, 128, 768)) #, dtype=torch.long))\n",
    "\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define the structure of Alice's network as a class. Even though Alice has a pre-trained model, the CrypTen will require this structure as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import curl.nn as nn\n",
    "\n",
    "class GPTConfig:\n",
    "    # Set dropout to 0 for inference. It is only needed for training\n",
    "    attn_dropout = 0.1\n",
    "    embed_dropout = 0.1\n",
    "    ff_dropout = 0.1\n",
    "\n",
    "    def __init__(\n",
    "        self, vocab_size, max_len, **kwargs\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "class GPT1Config(GPTConfig):\n",
    "    num_heads = 12\n",
    "    num_blocks = 12\n",
    "    embed_dim = 768\n",
    "\n",
    "vocab_size = 50257\n",
    "max_len = 1024\n",
    "\n",
    "config = GPT1Config(vocab_size, max_len)\n",
    "\n",
    "# class LayerNorm(nn.Module):\n",
    "#     \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "#     def __init__(self, ndim, bias):\n",
    "#         super(LayerNorm, self).__init__()\n",
    "#         self.weight = nn.Parameter(torch.ones(ndim))\n",
    "#         self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "\n",
    "        embed_dim = config.embed_dim\n",
    "        self.num_heads = config.num_heads\n",
    "        assert embed_dim % self.num_heads == 0, \"invalid heads and embedding dimension configuration\"\n",
    "\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_dropout = nn.Dropout(config.attn_dropout)\n",
    "        self.proj_dropout = nn.Dropout(config.ff_dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.tril(torch.ones(config.max_len, config.max_len))\n",
    "            .unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        with open(\"foo.txt\", \"w\") as file:\n",
    "            file.write(\"Your text goes here\")\n",
    "\n",
    "        level = logging.getLogger().level\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "        logging.info(\"==================\")\n",
    "        logging.info(\"In forward\" )\n",
    "        logging.info(\"==================\")\n",
    "\n",
    "        # x.shape == (batch_size, seq_len, embed_dim)\n",
    "        k_t = self.key(x).T\n",
    "        v = self.value(x)\n",
    "        q = self.query(x)\n",
    "        # shape == (batch_size, num_heads, seq_len, head_dim)\n",
    "        logging.info(f\"{k_t.shape=}\")\n",
    "        logging.info(f\"{v.shape=}\")\n",
    "        logging.info(f\"{q.shape=}\")\n",
    "\n",
    "        logging.info(\"KQV created\")\n",
    "        attn = torch.matmul(q, k_t) / torch.sqrt(q.size(-1))\n",
    "\n",
    "        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
    "        # attn = attn.masked_fill(self.mask == 0, float(\"-inf\"))\n",
    "        logging.info(\"masked fill\")\n",
    "\n",
    "        attn = self.attn_dropout(attn)\n",
    "\n",
    "        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        logging.info('here %s %s', attn.shape, v.shape)\n",
    "\n",
    "        y = torch.matmul(attn, v)\n",
    "        logging.info(\"matmul done\")\n",
    "\n",
    "        # y.shape == (batch_size, seq_len, embed_dim)\n",
    "        y = self.proj_dropout(self.proj(y))\n",
    "        logging.info(\"proj_dropout\")\n",
    "        logging.info(f\"{y.type}\")\n",
    "\n",
    "        logging.getLogger().setLevel(level)\n",
    "\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Block, self).__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.ln1 = nn.BatchNorm1d(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = MultiheadAttention(config)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(config.ff_dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.max_len = config.max_len\n",
    "        # self.tok_embed = nn.Embedding(\n",
    "        #     config.vocab_size, embed_dim\n",
    "        # )\n",
    "        # self.pos_embed = nn.Parameter(\n",
    "        #     torch.zeros(1, config.max_len, embed_dim)\n",
    "        # )\n",
    "        self.dropout = nn.Dropout(config.embed_dropout)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(config) for _ in range(config.num_blocks)]\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, config.vocab_size)\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        # embed_dim = config.embed_dim\n",
    "        # batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        assert seq_len <= self.max_len, \"sequence longer than model capacity\"\n",
    "\n",
    "        # tok_embedding = self.tok_embed(x)\n",
    "        # tok_embedding.shape == (batch_size, seq_len, embed_dim)\n",
    "        # pos_embedding = self.pos_embed[:, :seq_len, :]\n",
    "        # pos_embedding.shape == (1, seq_len, embed_dim)\n",
    "        # x = self.dropout(tok_embedding + pos_embedding)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        x = self.fc(x)\n",
    "        # x.shape == (batch_size, seq_len, vocab_size)\n",
    "        return x\n",
    "\n",
    "model = GPT(config)\n",
    "# model = Block(config)\n",
    "# model = MultiheadAttention(config)\n",
    "# model = LayerNorm(ndim=10, bias=1)\n",
    "\n",
    "crypten.common.serial.register_safe_class(GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define a helper routine `compute_accuracy` to make it easy to compute the accuracy of the output we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(output, labels):\n",
    "    pred = output.argmax(1)\n",
    "    correct = pred.eq(labels)\n",
    "    correct_count = correct.sum(0, keepdim=True).float()\n",
    "    accuracy = correct_count.mul_(100.0 / output.size(0))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypting a Pre-trained Model\n",
    "\n",
    "Assume that Alice has a pre-trained network ready to classify data. Let's see how we can use CrypTen to encrypt this network, so it can be used to classify data without revealing its parameters. We'll use the pre-trained model in `models/tutorial4_alice_model.pth` in this tutorial. As in Tutorial 3, we will assume Alice is using the rank 0 process, while Bob is using the rank 1 process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALICE = 0\n",
    "BOB = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CrypTen, encrypting PyTorch network is straightforward: we load a PyTorch model from file to the appropriate source, convert it to a CrypTen model and then encrypt it. Let us understand each of these steps.\n",
    "\n",
    "As we did with CrypTensors in Tutorial 3, we will use CrypTen's load functionality (i.e., `crypten.load`) to read a model from file to a particular source. The source is indicated by the keyword argument `src`. As in Tutorial 3, this src argument tells us the rank of the party we want to load the model to (and later, encrypt the model from). In addition, here we also need to provide a dummy model to tell CrypTen the model's structure. The dummy model is indicated by the keyword argument `dummy_model`. Note that unlike loading a tensor, the result from `crypten.load` is not encrypted. Instead, only the `src` party's model is populated from the file.\n",
    "\n",
    "Once the model is loaded, we call the function `from_pytorch`: this function sets up a CrypTen network from the PyTorch network. It takes the plaintext network as input as well as dummy input. The dummy input must be a `torch` tensor of the same shape as a potential input to the network, however the values inside the tensor do not matter.  \n",
    "\n",
    "Finally, we call `encrypt` on the CrypTen network to encrypt its parameters. Once we call the `encrypt` function, the models `encrypted` property will verify that the model parameters have been encrypted. (Encrypted CrypTen networks can also be decrypted using the `decrypt` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model to Alice\n",
    "# dummy_model = AliceNet()\n",
    "# plaintext_model = torch.load('models/gpt2.bin')\n",
    "# model.load_state_dict(plaintext_model)\n",
    "plaintext_model = model\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "# Encrypt the model from Alice:\n",
    "\n",
    "# 1. Create a dummy input with the same shape as the model input\n",
    "dummy_input = torch.empty((1024, 768), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# 2. Construct a CrypTen network with the trained model and dummy_input\n",
    "private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "\n",
    "# 3. Encrypt the CrypTen network with src=ALICE\n",
    "private_model.encrypt(src=ALICE)\n",
    "\n",
    "#Check that model is encrypted:\n",
    "print(\"Model successfully encrypted:\", private_model.encrypted)\n",
    "\n",
    "print(private_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Encrypted Data with Encrypted Model\n",
    "\n",
    "We can now use Alice's encrypted network to classify Bob's data. For this, we need to encrypt Bob's data as well, as we did in Tutorial 3 (recall that Bob has the rank 1 process). Once Alice's network and Bob's data are both encrypted, CrypTen inference is performed with essentially identical steps as in PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "# model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:==================\n",
      "INFO:root:In forward\n",
      "INFO:root:==================\n",
      "INFO:root:==================\n",
      "INFO:root:In Linear\n",
      "INFO:root:==================\n",
      "INFO:root:==================\n",
      "INFO:root:In Linear\n",
      "INFO:root:==================\n",
      "INFO:root:==================\n",
      "INFO:root:In Linear\n",
      "INFO:root:==================\n",
      "INFO:root:q=MPCTensor(\n",
      "\t_tensor=tensor([[-10347,  -2793,  -4438,  ...,   -382, -23082,  -2037],\n",
      "        [-11186,   8446,   5831,  ...,   5702,  -8415,  -9827],\n",
      "        [-11965, -16345,  -1484,  ..., -23496, -13105, -17982],\n",
      "        ...,\n",
      "        [  7657, -12255,   9758,  ...,   2460, -18667, -30977],\n",
      "        [  6498, -17621,  18986,  ...,   4994, -34420, -21247],\n",
      "        [ -5863,  -8031,  29161,  ...,   7533, -24777,  -2178]])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "started\n",
      "loading\n",
      "loaded gpt2\n",
      "dummy_input\n",
      "encrypting\n",
      "loading data\n",
      "flattened\n",
      "forward\n",
      "output_enc\n",
      "\tAccuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import curl.mpc as mpc\n",
    "import curl.communicator as comm\n",
    "\n",
    "print(\"starting\")\n",
    "labels = torch.load('/tmp/bob_test_labels.pth').long()\n",
    "count = 100 # For illustration purposes, we'll use only 100 samples for classification\n",
    "print(\"started\")\n",
    "\n",
    "# @mpc.run_multiprocess(world_size=2)\n",
    "def encrypt_model_and_data():\n",
    "    print(\"loading\")\n",
    "    # Load pre-trained model to Alice\n",
    "    # model = crypten.load_from_party('models/gpt2.bin', src=ALICE)\n",
    "    print(\"loaded gpt2\")\n",
    "    # Encrypt model from Alice\n",
    "    dummy_input = torch.empty((1024, 768)) #, dtype=torch.long)\n",
    "    print('dummy_input')\n",
    "    # private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
    "    private_model = model\n",
    "    print(\"encrypting\")\n",
    "    private_model.encrypt(src=ALICE)\n",
    "\n",
    "    # Load data to Bob\n",
    "    print('loading data')\n",
    "    # data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "    data_enc = crypten.cryptensor(torch.rand(1024, 768)) #, dtype=torch.long))\n",
    "    data_enc2 = data_enc[:count]\n",
    "    data_flatten = data_enc2.flatten(start_dim=1)\n",
    "    print('flattened')\n",
    "\n",
    "    # Classify the encrypted data\n",
    "    private_model.eval()\n",
    "    print(\"forward\")\n",
    "    output_enc = private_model(data_flatten)\n",
    "    print('output_enc')\n",
    "    # Compute the accuracy\n",
    "    output = output_enc.get_plain_text()\n",
    "    accuracy = compute_accuracy(output, labels[:count])\n",
    "    crypten.print(\"\\tAccuracy: {0:.4f}\".format(accuracy.item()))\n",
    "\n",
    "encrypt_model_and_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Encrypted Classification\n",
    "\n",
    "Finally, we will verify that CrypTen classification results in encrypted output, and that this output can be decrypted into meaningful labels. \n",
    "\n",
    "To see this, in this tutorial, we will just check whether the result is an encrypted tensor; in the next tutorial, we will look into the values of tensor and confirm the encryption. We will also decrypt the result. As we discussed before, Alice and Bob both have access to the decrypted output of the model, and can both use this to obtain the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/memo/Documents/curl/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/__/frht1s0n5hd1nnltt_cl9m1r0000gn/T/ipykernel_58278/2535009032.py\", line 4, in encrypt_model_and_data\n",
      "    plaintext_model = crypten.load_from_party('models/tutorial4_alice_model.pth', src=ALICE)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/Documents/curl/crypten/__init__.py\", line 337, in load_from_party\n",
      "    result = load_closure(f, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/serialization.py\", line 1040, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/serialization.py\", line 1073, in find_class\n",
      "    return super().find_class(mod_name, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'AliceNet' on <module '__main__'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m     crypten\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecrypted labels:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, pred)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mencrypt_model_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/curl/crypten/mpc/context.py:97\u001b[0m, in \u001b[0;36mrun_multiprocess.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[0;32m---> 97\u001b[0m     \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m was_initialized:\n\u001b[1;32m    100\u001b[0m     crypten\u001b[38;5;241m.\u001b[39minit()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/memo/Documents/curl/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/__/frht1s0n5hd1nnltt_cl9m1r0000gn/T/ipykernel_58278/2535009032.py\", line 4, in encrypt_model_and_data\n",
      "    plaintext_model = crypten.load_from_party('models/tutorial4_alice_model.pth', src=ALICE)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/Documents/curl/crypten/__init__.py\", line 356, in load_from_party\n",
      "    result = comm.get().broadcast_obj(None, src)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/Documents/curl/crypten/communicator/communicator.py\", line 201, in logging_wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/Documents/curl/crypten/communicator/distributed_communicator.py\", line 317, in broadcast_obj\n",
      "    dist.broadcast(size, src, group=group)\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 72, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/memo/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 1918, in broadcast\n",
      "    work.wait()\n",
      "RuntimeError: [/Users/runner/work/pytorch/pytorch/pytorch/third_party/gloo/gloo/transport/uv/unbound_buffer.cc:67] Timed out waiting 1800000ms for recv operation to complete\n"
     ]
    }
   ],
   "source": [
    "@mpc.run_multiprocess(world_size=2)\n",
    "def encrypt_model_and_data():\n",
    "    # Load pre-trained model to Alice\n",
    "    plaintext_model = crypten.load_from_party('models/tutorial4_alice_model.pth', src=ALICE)\n",
    "\n",
    "    # Encrypt model from Alice\n",
    "    dummy_input = torch.empty((1, 784))\n",
    "    private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "    private_model.encrypt(src=ALICE)\n",
    "\n",
    "    # Load data to Bob\n",
    "    data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=BOB)\n",
    "    data_enc2 = data_enc[:count]\n",
    "    data_flatten = data_enc2.flatten(start_dim=1)\n",
    "\n",
    "    # Classify the encrypted data\n",
    "    private_model.eval()\n",
    "    output_enc = private_model(data_flatten)\n",
    "\n",
    "    # Verify the results are encrypted:\n",
    "    crypten.print(\"Output tensor encrypted:\", crypten.is_encrypted_tensor(output_enc))\n",
    "\n",
    "    # Decrypting the result\n",
    "    output = output_enc.get_plain_text()\n",
    "\n",
    "    # Obtaining the labels\n",
    "    pred = output.argmax(dim=1)\n",
    "    crypten.print(\"Decrypted labels:\\n\", pred)\n",
    "\n",
    "encrypt_model_and_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This completes our tutorial. While we have used a simple network here to illustrate the concepts, CrypTen provides primitives to allow for encryption of substantially more complex networks. In our examples section, we demonstrate how CrypTen can be used to encrypt LeNet and ResNet, among others. \n",
    "\n",
    "Before exiting this tutorial, please clean up the files generated using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filenames = ['/tmp/alice_train.pth',\n",
    "             '/tmp/alice_train_labels.pth',\n",
    "             '/tmp/bob_test.pth',\n",
    "             '/tmp/bob_test_labels.pth']\n",
    "\n",
    "for fn in filenames:\n",
    "    if os.path.exists(fn): os.remove(fn)"
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "390894444956881"
  },
  "disseminate_notebook_info": {
   "bento_version": "20190826-030256",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "error": "The file located at '/data/users/shobha/fbsource/fbcode/bento/kernels/local/cryptenk/TARGETS' could not be found."
   },
   "no_uii": true,
   "notebook_number": "139932",
   "others_can_edit": true,
   "reviewers": "",
   "revision_id": "375902760006757",
   "tags": "",
   "tasks": "",
   "title": "Tutorial 4 -- Classification with Encrypted Neural Networks"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
