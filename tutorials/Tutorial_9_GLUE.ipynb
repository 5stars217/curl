{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification with Encrypted Neural Networks\n",
    "\n",
    "In this tutorial, we'll look at how we can achieve the <i>Model Hiding</i> application we discussed in the Introduction. That is, suppose say Alice has a trained model she wishes to keep private, and Bob has some data he wishes to classify while keeping it private. We will see how CrypTen allows Alice and Bob to coordinate and classify the data, while achieving their privacy requirements.\n",
    "\n",
    "To simulate this scenario, we will begin with Alice training a simple neural network on MNIST data. Then we'll see how Alice and Bob encrypt their network and data respectively, classify the encrypted data and finally decrypt the labels.\n",
    "\n",
    "## Setup\n",
    "\n",
    "We first import the `torch` and `crypten` libraries, and initialize `crypten`. We will use a helper script `mnist_utils.py` to split the public MNIST data into Alice's portion and Bob's portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ProcessGroupGloo.cpp:751] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] LUTs initialized for cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import crypten\n",
    "import crypten.nn as nn\n",
    "import math\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention(nn.Module):\n",
    "#     def __init__(self, embed_dim, num_heads):\n",
    "#         super(Attention, self).__init__()\n",
    "\n",
    "#         assert embed_dim % num_heads == 0, \"invalid heads and embedding dimension\"\n",
    "\n",
    "#         self.embed_dim = embed_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         self.search_dim = embed_dim // num_heads\n",
    "\n",
    "#         self.key = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.value = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.query = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size = x.shape[0]\n",
    "#         seq_len = x.shape[1]\n",
    "\n",
    "#         k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).permute(0, 2, 3, 1)\n",
    "#         v = self.value(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "#         q = self.query(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "\n",
    "#         attn = q.matmul(k_t) / math.sqrt(q.size(-1))\n",
    "#         attn = attn.softmax(dim=-1)\n",
    "#         y = attn.matmul(v)\n",
    "#         y = y.transpose(1, 2)\n",
    "#         y = y.reshape(batch_size, seq_len, self.embed_dim)\n",
    "#         return y\n",
    "\n",
    "\n",
    "# class BertBlock(nn.Module):\n",
    "#     def __init__(self, embed_dim, num_heads):\n",
    "#         super(BertBlock, self).__init__()\n",
    "#         embed_dim = embed_dim\n",
    "#         self.ln1 = nn.LayerNorm(embed_dim)\n",
    "#         self.ln2 = nn.LayerNorm(embed_dim)\n",
    "#         self.attn = Attention(embed_dim, num_heads)\n",
    "#         self.ff = nn.Sequential(\n",
    "#             nn.Linear(embed_dim, embed_dim * 4),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(embed_dim * 4, embed_dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.ln1(x + self.attn(x))\n",
    "#         x = self.ln2(x + self.ff(x))\n",
    "#         return x\n",
    "\n",
    "# class Bert(nn.Module):\n",
    "#     def __init__(self, embed_dim, num_heads, num_blocks, vocab_size, seq_len, full=True):\n",
    "#         super(Bert, self).__init__()\n",
    "#         self.full = full\n",
    "#         if full:\n",
    "#             self.word_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "#             self.pos_embed = nn.Parameter(torch.zeros(1, seq_len, embed_dim))\n",
    "#             self.type_embed = nn.Embedding(2, embed_dim)\n",
    "#             self.ln = nn.LayerNorm(embed_dim)\n",
    "#         self.blocks = nn.Sequential(\n",
    "#             *[BertBlock(embed_dim, num_heads) for _ in range(num_blocks)]\n",
    "#         )\n",
    "#         if full:\n",
    "#             self.pooler = nn.Linear(embed_dim, embed_dim)\n",
    "#             self.classifier = nn.Linear(embed_dim, 2)\n",
    "\n",
    "#     def forward(self, x, target=None):\n",
    "#         if self.full:\n",
    "#             word_embedding = self.word_embed(x[\"input_ids\"])\n",
    "#             pos_embedding = self.pos_embed(x)[:, :x[\"input_ids\"].size()[1], :]\n",
    "#             type_embedding = self.type_embed(x[\"token_type_ids\"])\n",
    "#             x = word_embedding + pos_embedding + type_embedding\n",
    "#             x = self.ln(x)\n",
    "#         x = self.blocks(x)\n",
    "#         if self.full:\n",
    "#             x = self.pooler(x[:, 0, :])\n",
    "#             x = x.tanh()\n",
    "#             x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# model = Bert(768, 12, 12, 30522, 1024, True) # bert base 13.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, max_seq_length):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        self.position_embeddings = nn.Embedding(max_seq_length, emb_size)\n",
    "        self.token_type_embeddings = nn.Embedding(2, emb_size)\n",
    "        self.LayerNorm = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        word_emb = self.word_embeddings(input_ids)\n",
    "        pos_emb = self.position_embeddings.weight[:input_ids.size()[1], :]\n",
    "        type_emb = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        emb = word_emb + pos_emb + type_emb\n",
    "        emb = self.LayerNorm(emb)\n",
    "\n",
    "        return emb\n",
    "\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = emb_size // self.n_heads\n",
    "        self.query = nn.Linear(emb_size, emb_size)\n",
    "        self.key = nn.Linear(emb_size, emb_size)\n",
    "        self.value = nn.Linear(emb_size, emb_size)\n",
    "\n",
    "    def forward(self, emb):\n",
    "        B, T, C = emb.shape  # batch size, sequence length, embedding size\n",
    "\n",
    "        q = self.query(emb).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        k = self.key(emb).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        v = self.value(emb).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "\n",
    "        weights = q @ k.transpose(-2, -1) * self.head_size**-0.5\n",
    "\n",
    "        weights = weights.softmax(dim=-1)\n",
    "\n",
    "        emb_rich = weights @ v\n",
    "        emb_rich = emb_rich.transpose(1, 2).reshape(B, T, C)\n",
    "\n",
    "        return emb_rich\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(emb_size, emb_size)\n",
    "        self.LayerNorm = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, emb_rich, emb):\n",
    "        x = self.dense(emb_rich)\n",
    "        x = x + emb\n",
    "        out = self.LayerNorm(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(emb_size, n_heads)\n",
    "        self.output = BertSelfOutput(emb_size)\n",
    "\n",
    "    def forward(self, emb):\n",
    "        emb_rich = self.self(emb)\n",
    "        out = self.output(emb_rich, emb)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(emb_size, 4 * emb_size)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, att_out):\n",
    "        x = self.dense(att_out)\n",
    "        out = self.gelu(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(4 * emb_size, emb_size)\n",
    "        self.LayerNorm = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, intermediate_out, att_out):\n",
    "        x = self.dense(intermediate_out)\n",
    "        x = x + att_out\n",
    "        out = self.LayerNorm(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads ):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(emb_size, n_heads)\n",
    "        self.intermediate = BertIntermediate(emb_size)\n",
    "        self.output = BertOutput(emb_size)\n",
    "\n",
    "    def forward(self, emb):\n",
    "        att_out = self.attention(emb)\n",
    "        intermediate_out = self.intermediate(att_out)\n",
    "        out = self.output(intermediate_out, att_out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.layer = nn.ModuleList([BertLayer(emb_size, n_heads) for i in range(n_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layer:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(emb_size, emb_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, encoder_out):\n",
    "        pool_first_token = encoder_out[:, 0]\n",
    "        out = self.dense(pool_first_token)\n",
    "        out = self.tanh(out)\n",
    "        return out\n",
    "\n",
    "class BertModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, seq_len, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.embeddings = BertEmbeddings(vocab_size, emb_size, seq_len)\n",
    "        self.encoder = BertEncoder(emb_size, n_heads, n_layers)\n",
    "        self.pooler = BertPooler(emb_size)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        emb = self.embeddings(input_ids, token_type_ids)\n",
    "        out = self.encoder(emb)\n",
    "        pooled_out = self.pooler(out)\n",
    "        return out, pooled_out\n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, seq_len, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel(vocab_size, emb_size, seq_len, n_heads, n_layers)\n",
    "        self.classifier = nn.Linear(emb_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        _, pooled_out = self.bert(input_ids, token_type_ids)\n",
    "        logits = self.classifier(pooled_out)\n",
    "        return logits\n",
    "\n",
    "# model = LLM(Bert(768, 12, 12, 30522, 1024))\n",
    "model = BertForSequenceClassification(28996, 768, 512, 12, 12)\n",
    "# model = BertForSequenceClassification(30522, 128, 512, 2, 2) # tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight: torch.Size([28996, 768])\n",
      "bert.embeddings.position_embeddings.weight: torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight: torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight: torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.pooler.dense.weight: torch.Size([768, 768])\n",
      "bert.pooler.dense.bias: torch.Size([768])\n",
      "classifier.weight: torch.Size([2, 768])\n",
      "classifier.bias: torch.Size([2])\n",
      "n_weight=108208896, n_bias=102914, n_param=108311810\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "bert_model = BertForSequenceClassification.from_pretrained('gchhablani/bert-base-cased-finetuned-qnli')\n",
    "# bert_model = BertForSequenceClassification.from_pretrained('M-FAC/bert-tiny-finetuned-qnli')\n",
    "bert_model.eval()\n",
    "\n",
    "# Access the model's weights\n",
    "weights = bert_model.state_dict()\n",
    "\n",
    "# Modify the weights or perform any operation you desire\n",
    "# Example: Print the shape of each weight tensor\n",
    "o = 0\n",
    "b = 0\n",
    "for name, weight in weights.items():\n",
    "    if \"weight\" in str(name):\n",
    "        print(f\"{name}: {weight.size()}\")\n",
    "        p = 1\n",
    "        for w in weight.size():\n",
    "            p *= w\n",
    "        o += p\n",
    "    elif \"bias\" in str(name):\n",
    "        print(f\"{name}: {weight.size()}\")\n",
    "        p = 1\n",
    "        for w in weight.size():\n",
    "            p *= w\n",
    "        b += p\n",
    "    else:\n",
    "        print(f\"else {name}: {weight.size()}\")\n",
    "print(f\"n_weight={o}, n_bias={b}, n_param={o+b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(weights)\n",
    "\n",
    "# model.word_embed.weight = weights[\"bert.embeddings.word_embeddings.weight\"]\n",
    "# model.pos_embed.data = weights[\"bert.embeddings.position_embeddings.weight\"][None, :, :]\n",
    "# model.type_embed.weight = weights[\"bert.embeddings.token_type_embeddings.weight\"]\n",
    "# model.ln.weight = weights[\"bert.embeddings.LayerNorm.weight\"]\n",
    "# model.ln.bias = weights[\"bert.embeddings.LayerNorm.bias\"]\n",
    "# for m in range(len(model.blocks._modules)):\n",
    "#     layer = \"bert.encoder.layer.\"\n",
    "#     model.blocks._modules[str(m)].attn.query.weight = weights[layer+str(m)+\".attention.self.query.weight\"]\n",
    "#     model.blocks._modules[str(m)].attn.query.bias = weights[layer+str(m)+\".attention.self.query.bias\"]\n",
    "#     model.blocks._modules[str(m)].attn.key.weight = weights[layer+str(m)+\".attention.self.key.weight\"]\n",
    "#     model.blocks._modules[str(m)].attn.key.bias = weights[layer+str(m)+\".attention.self.key.bias\"]\n",
    "#     model.blocks._modules[str(m)].attn.value.weight = weights[layer+str(m)+\".attention.self.value.weight\"]\n",
    "#     model.blocks._modules[str(m)].attn.value.bias = weights[layer+str(m)+\".attention.self.value.bias\"]\n",
    "#     model.blocks._modules[str(m)].attn.proj.weight = weights[layer+str(m)+\".attention.output.dense.weight\"] # .t()\n",
    "#     model.blocks._modules[str(m)].attn.proj.bias = weights[layer+str(m)+\".attention.output.dense.bias\"]\n",
    "#     model.blocks._modules[str(m)].ln1.weight = weights[layer+str(m)+\".attention.output.LayerNorm.weight\"]\n",
    "#     model.blocks._modules[str(m)].ln1.bias = weights[layer+str(m)+\".attention.output.LayerNorm.bias\"]\n",
    "#     model.blocks._modules[str(m)].ff._modules['0'].weight = weights[layer+str(m)+\".intermediate.dense.weight\"] # .t()\n",
    "#     model.blocks._modules[str(m)].ff._modules['0'].bias = weights[layer+str(m)+\".intermediate.dense.bias\"]\n",
    "#     model.blocks._modules[str(m)].ff._modules['2'].weight = weights[layer+str(m)+\".output.dense.weight\"] # .t()\n",
    "#     model.blocks._modules[str(m)].ff._modules['2'].bias = weights[layer+str(m)+\".output.dense.bias\"]\n",
    "#     model.blocks._modules[str(m)].ln2.weight = weights[layer+str(m)+\".output.LayerNorm.weight\"]\n",
    "#     model.blocks._modules[str(m)].ln2.bias = weights[layer+str(m)+\".output.LayerNorm.bias\"]\n",
    "# model.pooler.weight = weights[\"bert.pooler.dense.weight\"] # .t()\n",
    "# model.pooler.bias = weights[\"bert.pooler.dense.bias\"]\n",
    "# model.classifier.weight = weights[\"classifier.weight\"] # .t()\n",
    "# model.classifier.bias = weights[\"classifier.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.5781,  0.1473]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gchhablani/bert-base-cased-finetuned-qnli\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"M-FAC/bert-tiny-finetuned-qnli\")\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = bert_model(**inputs)\n",
    "realput = outputs\n",
    "print(realput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def load_tsv(data_file, max_seq_len, delimiter='\\t'):\n",
    "    '''Load a tsv '''\n",
    "    sentences = []\n",
    "    targets = []\n",
    "    with codecs.open(data_file, 'r', 'utf-8') as data_fh:\n",
    "        for _ in range(1):\n",
    "            data_fh.readline()\n",
    "        for row in data_fh:\n",
    "            row = row.strip().split(delimiter)\n",
    "            sentences.append(tokenizer(row[1][:512], row[2][:512], return_tensors=\"pt\"))\n",
    "            targets.append(1*(row[3] == \"not_entailment\"))\n",
    "    return sentences, targets\n",
    "\n",
    "data, targets = load_tsv(\"GLUE-baselines/glue_data/QNLI/dev.tsv\", 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9099)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for label in range(len(data)):\n",
    "    outputs = bert_model(**data[label])\n",
    "    count += targets[label] == outputs.logits.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output_enc\n",
      "output.shape=torch.Size([1, 2])\n",
      "output=tensor([[ 2.1267, -1.6942]])\n"
     ]
    }
   ],
   "source": [
    "model.encrypt(src=0)\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "x = {}\n",
    "x['input_ids'] = crypten.cryptensor(data[0][\"input_ids\"], precision = 0)\n",
    "x['token_type_ids'] = crypten.cryptensor(data[0][\"token_type_ids\"], precision = 0)\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "x = model(x['input_ids'], x['token_type_ids'])\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = x.get_plain_text()\n",
    "print(f\"{output.shape=}\")\n",
    "print(f\"{output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7345, -2.2678]])\n"
     ]
    }
   ],
   "source": [
    "label = 3\n",
    "x = {}\n",
    "x['input_ids'] = crypten.cryptensor(data[label][\"input_ids\"], precision = 0)\n",
    "x['token_type_ids'] = crypten.cryptensor(data[label][\"token_type_ids\"], precision = 0)\n",
    "outputs = model(x['input_ids'], x['token_type_ids'])\n",
    "cleartext = outputs.get_plain_text()\n",
    "print(cleartext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0014, -1.6264]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5682,  2.9418]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8672,  2.4340]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 3.1729, -2.6355]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.2055,  1.8402]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6816,  3.0014]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.3215,  1.2353]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.7192,  2.9996]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.8530,  3.0773]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 3.5189, -2.9471]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "count = 0\n",
    "for i in range(10):\n",
    "    outputs = bert_model(**data[i])\n",
    "    print(outputs.logits)\n",
    "    count += targets[i] == outputs.logits.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "count = 0\n",
    "for label in range(1000):\n",
    "    x = {}\n",
    "    x['input_ids'] = crypten.cryptensor(data[label][\"input_ids\"], precision = 0)\n",
    "    x['token_type_ids'] = crypten.cryptensor(data[label][\"token_type_ids\"], precision = 0)\n",
    "    outputs = model(x['input_ids'], x['token_type_ids'])\n",
    "    cleartext = outputs.get_plain_text()\n",
    "    print(cleartext)\n",
    "    count += targets[label] == cleartext.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0731e+14,  4.7462e+13]])\n",
      "tensor([[2.6860e+13, 9.0002e+13]])\n",
      "tensor([[-5.0927e+13, -1.0232e+14]])\n",
      "tensor([[-6.8693e+13, -6.0797e+13]])\n",
      "tensor([[-2.8268e+13, -8.9721e+13]])\n",
      "tensor([[-7.4354e+13, -6.7186e+13]])\n",
      "tensor([[3.1812e+13, 8.1238e+13]])\n",
      "tensor([[ 1.3858e+14, -1.3209e+14]])\n",
      "tensor([[-1.3398e+14, -1.4564e+13]])\n",
      "tensor([[-8.6160e+13,  9.1290e+13]])\n",
      "tensor([[-5.9247e+13,  1.1057e+14]])\n",
      "tensor([[-2.4512e+11,  5.3922e+12]])\n",
      "tensor([[-9.2227e+13,  9.4108e+13]])\n",
      "tensor([[ 3.1355e+12, -1.1937e+14]])\n",
      "tensor([[-1.2403e+14, -7.3490e+13]])\n",
      "tensor([[-5.7338e+13, -3.2418e+13]])\n",
      "tensor([[-1.1355e+14, -4.5022e+13]])\n",
      "tensor([[6.0592e+13, 5.1518e+13]])\n",
      "tensor([[ 8.1546e+13, -7.4386e+13]])\n",
      "tensor([[ 4.2795e+13, -1.0965e+14]])\n",
      "tensor([[1.2805e+14, 4.6305e+13]])\n",
      "tensor([[6.9031e+13, 3.2738e+12]])\n",
      "tensor([[4.9871e+13, 6.0588e+13]])\n",
      "tensor([[-4.6483e+13, -6.8444e+13]])\n",
      "tensor([[-3.1408e+13,  1.3933e+14]])\n",
      "tensor([[-1.2467e+13, -4.6917e+13]])\n",
      "tensor([[-1.1689e+14, -4.2620e+12]])\n",
      "tensor([[ 1.6816e+13, -1.2708e+14]])\n",
      "tensor([[ 1.1773e+14, -9.7159e+13]])\n",
      "tensor([[-1.3226e+14,  1.2629e+14]])\n",
      "tensor([[1.5171e+13, 4.6779e+13]])\n",
      "tensor([[6.7672e+13, 1.2220e+14]])\n",
      "tensor([[8.1743e+13, 2.1920e+13]])\n",
      "tensor([[2.3260e+13, 3.8624e+13]])\n",
      "tensor([[7.2345e+13, 8.1351e+12]])\n",
      "tensor([[-1.2707e+14,  9.8354e+13]])\n",
      "tensor([[ 3.3426e+13, -4.1061e+13]])\n",
      "tensor([[-3.9100e+13, -6.5740e+13]])\n",
      "tensor([[8.4496e+13, 7.6741e+13]])\n",
      "tensor([[-1.1528e+14, -1.2429e+14]])\n",
      "tensor([[ 1.1414e+14, -4.3566e+13]])\n",
      "tensor([[ 5.4990e+13, -4.0682e+13]])\n",
      "tensor([[-1.1969e+14, -1.1546e+14]])\n",
      "tensor([[-9.0058e+13, -4.2162e+13]])\n",
      "tensor([[-7.7111e+13,  1.3817e+13]])\n",
      "tensor([[-5.5899e+13, -3.4039e+13]])\n",
      "tensor([[-1.3045e+14, -1.2636e+13]])\n",
      "tensor([[ 1.8292e+13, -3.2553e+13]])\n",
      "tensor([[5.1906e+13, 1.5581e+13]])\n",
      "tensor([[-1.2312e+14, -1.1310e+14]])\n",
      "tensor([[-9.7626e+13, -4.1279e+13]])\n",
      "tensor([[-2.1483e+13,  6.0669e+13]])\n",
      "tensor([[ 2.9299e+13, -5.2482e+13]])\n",
      "tensor([[-5.1535e+13, -1.3559e+14]])\n",
      "tensor([[1.3405e+14, 1.8868e+13]])\n",
      "tensor([[-4.3435e+13,  8.7436e+13]])\n",
      "tensor([[-1.1610e+14,  8.5794e+13]])\n",
      "tensor([[-1.0784e+14, -3.9435e+13]])\n",
      "tensor([[ 8.2190e+13, -8.8174e+12]])\n",
      "tensor([[1.2035e+14, 9.2430e+13]])\n",
      "tensor([[-7.1341e+13, -6.6051e+13]])\n",
      "tensor([[-1.2129e+14, -1.3228e+14]])\n",
      "tensor([[-1.8038e+13,  1.0523e+14]])\n",
      "tensor([[ 2.8569e+13, -8.2339e+13]])\n",
      "tensor([[-1.0697e+13, -6.5698e+13]])\n",
      "tensor([[4.1864e+13, 2.9136e+13]])\n",
      "tensor([[3.0330e+11, 9.9310e+13]])\n",
      "tensor([[1.1027e+14, 2.2043e+13]])\n",
      "tensor([[ 1.0927e+14, -1.6636e+13]])\n",
      "tensor([[-4.3183e+12, -9.7685e+13]])\n",
      "tensor([[-7.3799e+13, -3.4401e+13]])\n",
      "tensor([[1.1826e+14, 2.4377e+13]])\n",
      "tensor([[3.8661e+13, 8.0780e+13]])\n",
      "tensor([[-9.7062e+13, -1.0688e+13]])\n",
      "tensor([[1.7787e+13, 4.5282e+13]])\n",
      "tensor([[1.1432e+13, 1.2101e+14]])\n",
      "tensor([[-8.9525e+13, -1.1475e+14]])\n",
      "tensor([[ 3.8298e+12, -7.7462e+13]])\n",
      "tensor([[ 1.1668e+14, -2.2642e+13]])\n",
      "tensor([[ 5.0893e+13, -1.2070e+14]])\n",
      "tensor([[ 2.4094e+13, -1.2655e+14]])\n",
      "tensor([[-6.1758e+13, -4.1056e+13]])\n",
      "tensor([[3.3617e+13, 5.2888e+13]])\n",
      "tensor([[ 3.3803e+13, -1.8056e+13]])\n",
      "tensor([[2.2659e+13, 1.2526e+14]])\n",
      "tensor([[8.2280e+13, 1.3538e+14]])\n",
      "tensor([[-4.5557e+13,  9.0727e+13]])\n",
      "tensor([[-1.1405e+14, -7.4137e+13]])\n",
      "tensor([[ 1.9316e+13, -4.4474e+12]])\n",
      "tensor([[ 3.5333e+13, -2.5389e+13]])\n",
      "tensor([[-1.1721e+14, -1.0772e+13]])\n",
      "tensor([[ 1.0990e+14, -1.2206e+14]])\n",
      "tensor([[ 1.1160e+14, -1.1916e+14]])\n",
      "tensor([[-1.1756e+14,  8.3082e+11]])\n",
      "tensor([[ 4.1600e+13, -1.0243e+14]])\n",
      "tensor([[1.1361e+14, 7.6216e+13]])\n",
      "tensor([[ 1.0532e+14, -1.0276e+12]])\n",
      "tensor([[1.1586e+14, 9.0810e+13]])\n",
      "tensor([[ 1.1709e+14, -3.3948e+13]])\n",
      "tensor([[-1.2830e+14,  8.6852e+13]])\n",
      "tensor([[9.3449e+13, 2.1301e+13]])\n",
      "tensor([[ 4.5705e+13, -1.2209e+14]])\n",
      "tensor([[6.1128e+12, 3.0289e+13]])\n",
      "tensor([[-1.0013e+14,  1.2157e+13]])\n",
      "tensor([[ 1.2901e+14, -8.6533e+13]])\n",
      "tensor([[-9.3496e+13,  7.1045e+12]])\n",
      "tensor([[-3.3929e+13, -3.7411e+13]])\n",
      "tensor([[ 1.1274e+14, -8.8288e+13]])\n",
      "tensor([[-9.0947e+13,  6.5441e+13]])\n",
      "tensor([[-1.0454e+14,  1.3163e+14]])\n",
      "tensor([[-4.0789e+13,  1.0044e+14]])\n",
      "tensor([[1.3035e+14, 2.7748e+13]])\n",
      "tensor([[ 2.1700e+13, -1.1266e+14]])\n",
      "tensor([[ 5.0772e+13, -2.0300e+13]])\n",
      "tensor([[-9.0578e+13,  4.8824e+13]])\n",
      "tensor([[ 1.5432e+13, -9.8506e+12]])\n",
      "tensor([[-7.8451e+13,  8.8819e+13]])\n",
      "tensor([[-1.3983e+14,  1.2645e+14]])\n",
      "tensor([[ 5.5754e+13, -6.6961e+13]])\n",
      "tensor([[-6.9134e+13, -1.2176e+14]])\n",
      "tensor([[ 3.9141e+13, -1.2104e+14]])\n",
      "tensor([[-2.3482e+12, -8.9944e+13]])\n",
      "tensor([[-7.4944e+13, -5.5320e+13]])\n",
      "tensor([[ 7.7102e+12, -4.3558e+13]])\n",
      "tensor([[ 3.2547e+13, -6.9403e+13]])\n",
      "tensor([[-7.2284e+13,  7.9108e+13]])\n",
      "tensor([[-4.1465e+13,  8.1026e+13]])\n",
      "tensor([[8.8652e+13, 1.0632e+13]])\n",
      "tensor([[4.2291e+13, 1.3601e+14]])\n",
      "tensor([[3.2563e+13, 6.9652e+13]])\n",
      "tensor([[ 6.8141e+13, -1.3978e+14]])\n",
      "tensor([[4.2797e+13, 3.9712e+13]])\n",
      "tensor([[ 1.7113e+13, -7.1123e+13]])\n",
      "tensor([[-1.3100e+14, -7.1779e+12]])\n",
      "tensor([[1.1389e+14, 9.6368e+12]])\n",
      "tensor([[4.5429e+13, 1.3864e+14]])\n",
      "tensor([[-3.6365e+13, -5.8313e+12]])\n",
      "tensor([[ 1.0082e+14, -2.8290e+13]])\n",
      "tensor([[6.7087e+13, 7.7607e+13]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8070)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label in range(861, 1000):\n",
    "    x = {}\n",
    "    x['input_ids'] = crypten.cryptensor(data[label][\"input_ids\"], precision = 0)\n",
    "    x['token_type_ids'] = crypten.cryptensor(data[label][\"token_type_ids\"], precision = 0)\n",
    "    outputs = model(x['input_ids'], x['token_type_ids'])\n",
    "    cleartext = outputs.get_plain_text()\n",
    "    print(cleartext)\n",
    "    count += targets[label] == cleartext.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BertForSequenceClassification' object has no attribute 'word_embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m crypten\u001b[38;5;241m.\u001b[39mcryptensor(data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# x['input_ids'] = crypten.cryptensor(torch.tensor([1]), precision = 0)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# x['token_type_ids'] = crypten.cryptensor(torch.tensor([0, 1, 0, 1]), precision = 0)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m word_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embed\u001b[49m(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m pos_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpos_embed(x)[:, :x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m], :]\n\u001b[1;32m     12\u001b[0m type_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtype_embed(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/curl/crypten/nn/module.py:553\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m buffers:\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m buffers[name]\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m    555\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'word_embed'"
     ]
    }
   ],
   "source": [
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# Classify the encrypted data\n",
    "print(\"forward\")\n",
    "x = {}\n",
    "x['input_ids'] = crypten.cryptensor(data[0][\"input_ids\"], precision = 0)\n",
    "x['token_type_ids'] = crypten.cryptensor(data[0][\"token_type_ids\"], precision = 0)\n",
    "# x['input_ids'] = crypten.cryptensor(torch.tensor([1]), precision = 0)\n",
    "# x['token_type_ids'] = crypten.cryptensor(torch.tensor([0, 1, 0, 1]), precision = 0)\n",
    "word_embedding = model.word_embed(x[\"input_ids\"])\n",
    "pos_embedding = model.pos_embed(x)[:, :x[\"input_ids\"].size()[1], :]\n",
    "type_embedding = model.type_embed(x[\"token_type_ids\"])\n",
    "x = word_embedding + pos_embedding + type_embedding\n",
    "x = model.ln(x)\n",
    "# v = '0'\n",
    "# x = model.blocks._modules[v].attn(x)\n",
    "x = model.blocks._modules['0'](x)\n",
    "x = model.blocks._modules['1'](x)\n",
    "x = model.blocks._modules['2'](x)\n",
    "x = model.blocks._modules['3'](x)\n",
    "x = model.blocks._modules['4'](x)\n",
    "x = model.blocks._modules['5'](x)\n",
    "x = model.blocks._modules['6'](x)\n",
    "x = model.blocks._modules['7'](x)\n",
    "x = model.blocks._modules['8'](x)\n",
    "x = model.blocks._modules['9'](x)\n",
    "x = model.blocks._modules['10'](x)\n",
    "x = model.blocks._modules['11'](x)\n",
    "x = model.pooler(x[:, 0, :])\n",
    "x = x.tanh()\n",
    "x = model.classifier(x)\n",
    "\n",
    "# x = model(x)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = x.get_plain_text()\n",
    "print(f\"{output.shape=}\")\n",
    "print(f\"{output=}\")\n",
    "print(f\"{output.max()} {output.min()}\")\n",
    "print(f\"{output.mean()} {output.var()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention(torch.nn.Module):\n",
    "#     def __init__(self, embed_dim, num_heads):\n",
    "#         super(Attention, self).__init__()\n",
    "\n",
    "#         assert embed_dim % num_heads == 0, \"invalid heads and embedding dimension\"\n",
    "\n",
    "#         self.embed_dim = embed_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         self.search_dim = embed_dim // num_heads\n",
    "\n",
    "#         self.key = torch.nn.Linear(embed_dim, embed_dim)\n",
    "#         self.value = torch.nn.Linear(embed_dim, embed_dim)\n",
    "#         self.query = torch.nn.Linear(embed_dim, embed_dim)\n",
    "#         self.proj = torch.nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size = x.shape[0]\n",
    "#         seq_len = x.shape[1]\n",
    "\n",
    "#         k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).permute(0, 2, 3, 1)\n",
    "#         v = self.value(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "#         q = self.query(x).reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "\n",
    "#         attn = q.matmul(k_t) / math.sqrt(q.size(-1))\n",
    "#         attn = attn.softmax(dim=-1)\n",
    "#         y = attn.matmul(v)\n",
    "#         y = y.transpose(1, 2)\n",
    "#         y = y.reshape(batch_size, seq_len, self.embed_dim)\n",
    "#         return y\n",
    "\n",
    "\n",
    "# class BertBlock(torch.nn.Module):\n",
    "#     def __init__(self, embed_dim, num_heads):\n",
    "#         super(BertBlock, self).__init__()\n",
    "#         embed_dim = embed_dim\n",
    "#         self.ln1 = torch.nn.LayerNorm(embed_dim)\n",
    "#         self.ln2 = torch.nn.LayerNorm(embed_dim)\n",
    "#         self.attn = Attention(embed_dim, num_heads)\n",
    "#         self.ff = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(embed_dim, embed_dim * 4),\n",
    "#             torch.nn.GELU(),\n",
    "#             torch.nn.Linear(embed_dim * 4, embed_dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.ln1(x + self.attn(x))\n",
    "#         x = self.ln2(x + self.ff(x))\n",
    "#         return x\n",
    "\n",
    "# class Bert(torch.nn.Module):\n",
    "#     def __init__(self, embed_dim, num_heads, num_blocks, vocab_size, seq_len, full=True):\n",
    "#         super(Bert, self).__init__()\n",
    "#         self.full = full\n",
    "#         if full:\n",
    "#             self.word_embed = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "#             self.pos_embed = torch.nn.Parameter(torch.zeros(1, seq_len, embed_dim))\n",
    "#             self.type_embed = torch.nn.Embedding(2, embed_dim)\n",
    "#             self.ln = torch.nn.LayerNorm(embed_dim)\n",
    "#         self.blocks = torch.nn.Sequential(\n",
    "#             *[BertBlock(embed_dim, num_heads) for _ in range(num_blocks)]\n",
    "#         )\n",
    "#         if full:\n",
    "#             self.pooler = torch.nn.Linear(embed_dim, embed_dim)\n",
    "#             self.classifier = torch.nn.Linear(embed_dim, 2)\n",
    "\n",
    "#     def forward(self, x, target=None):\n",
    "#         if self.full:\n",
    "#             word_embedding = self.word_embed(x[\"input_ids\"])\n",
    "#             pos_embedding = self.pos_embed[:, :x[\"input_ids\"].size()[1], :]\n",
    "#             type_embedding = self.type_embed(x[\"token_type_ids\"])\n",
    "#             x = word_embedding + pos_embedding + type_embedding\n",
    "#             x = self.ln(x)\n",
    "#         x = self.blocks(x)\n",
    "#         if self.full:\n",
    "#             x = self.pooler(x[:, 0, :])\n",
    "#             x = x.tanh()\n",
    "#             x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# plain_model = Bert(768, 12, 12, 30522, 1024, True) # bert base 13.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, max_seq_length):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        self.position_embeddings = nn.Embedding(max_seq_length, emb_size)\n",
    "        self.token_type_embeddings = nn.Embedding(2, emb_size)\n",
    "        self.LayerNorm = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        word_emb = self.word_embeddings(input_ids)\n",
    "        pos_emb = self.position_embeddings.weight[:input_ids.size()[1], :]\n",
    "        type_emb = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        emb = word_emb + pos_emb + type_emb\n",
    "        emb = self.LayerNorm(emb)\n",
    "\n",
    "        return emb\n",
    "\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = emb_size // self.n_heads\n",
    "        self.query = nn.Linear(emb_size, emb_size)\n",
    "        self.key = nn.Linear(emb_size, emb_size)\n",
    "        self.value = nn.Linear(emb_size, emb_size)\n",
    "\n",
    "    def forward(self, emb):\n",
    "        B, T, C = emb.shape  # batch size, sequence length, embedding size\n",
    "\n",
    "        q = self.query(emb).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        k = self.key(emb).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        v = self.value(emb).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "\n",
    "        weights = q @ k.transpose(-2, -1) * self.head_size**-0.5\n",
    "\n",
    "        weights = weights.softmax(dim=-1)\n",
    "\n",
    "        emb_rich = weights @ v\n",
    "        emb_rich = emb_rich.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        return emb_rich\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(emb_size, emb_size)\n",
    "        self.LayerNorm = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, emb_rich, emb):\n",
    "        x = self.dense(emb_rich)\n",
    "        x = x + emb\n",
    "        out = self.LayerNorm(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(emb_size, n_heads)\n",
    "        self.output = BertSelfOutput(emb_size)\n",
    "\n",
    "    def forward(self, emb):\n",
    "        emb_rich = self.self(emb)\n",
    "        out = self.output(emb_rich, emb)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(emb_size, 4 * emb_size)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, att_out):\n",
    "        x = self.dense(att_out)\n",
    "        out = self.gelu(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(4 * emb_size, emb_size)\n",
    "        self.LayerNorm = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, intermediate_out, att_out):\n",
    "        x = self.dense(intermediate_out)\n",
    "        x = x + att_out\n",
    "        out = self.LayerNorm(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads ):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(emb_size, n_heads)\n",
    "        self.intermediate = BertIntermediate(emb_size)\n",
    "        self.output = BertOutput(emb_size)\n",
    "\n",
    "    def forward(self, emb):\n",
    "        att_out = self.attention(emb)\n",
    "        intermediate_out = self.intermediate(att_out)\n",
    "        out = self.output(intermediate_out, att_out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, emb_size, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.layer = nn.ModuleList([BertLayer(emb_size, n_heads) for i in range(n_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layer:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(emb_size, emb_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, encoder_out):\n",
    "        pool_first_token = encoder_out[:, 0]\n",
    "        out = self.dense(pool_first_token)\n",
    "        out = self.tanh(out)\n",
    "        return out\n",
    "\n",
    "class BertModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, seq_len, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.embeddings = BertEmbeddings(vocab_size, emb_size, seq_len)\n",
    "        self.encoder = BertEncoder(emb_size, n_heads, n_layers)\n",
    "        self.pooler = BertPooler(emb_size)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        emb = self.embeddings(input_ids, token_type_ids)\n",
    "        out = self.encoder(emb)\n",
    "        pooled_out = self.pooler(out)\n",
    "        return out, pooled_out\n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, seq_len, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel(vocab_size, emb_size, seq_len, n_heads, n_layers)\n",
    "        self.classifier = nn.Linear(emb_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        _, pooled_out = self.bert(input_ids, token_type_ids)\n",
    "        logits = self.classifier(pooled_out)\n",
    "        return logits\n",
    "\n",
    "# model = LLM(Bert(768, 12, 12, 30522, 1024))\n",
    "model = BertForSequenceClassification(28996, 768, 512, 12, 12)\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain_model.word_embed.weight = torch.nn.Parameter(weights[\"bert.embeddings.word_embeddings.weight\"])\n",
    "# plain_model.pos_embed.data = torch.nn.Parameter(weights[\"bert.embeddings.position_embeddings.weight\"][None, :, :])\n",
    "# plain_model.type_embed.weight = torch.nn.Parameter(weights[\"bert.embeddings.token_type_embeddings.weight\"])\n",
    "# plain_model.ln.weight = torch.nn.Parameter(weights[\"bert.embeddings.LayerNorm.weight\"])\n",
    "# plain_model.ln.bias = torch.nn.Parameter(weights[\"bert.embeddings.LayerNorm.bias\"])\n",
    "# for m in range(len(plain_model.blocks._modules)):\n",
    "#     layer = \"bert.encoder.layer.\"\n",
    "#     plain_model.blocks._modules[str(m)].attn.query.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.query.weight\"])\n",
    "#     plain_model.blocks._modules[str(m)].attn.query.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.query.bias\"])\n",
    "#     plain_model.blocks._modules[str(m)].attn.key.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.key.weight\"])\n",
    "#     plain_model.blocks._modules[str(m)].attn.key.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.key.bias\"])\n",
    "#     plain_model.blocks._modules[str(m)].attn.value.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.value.weight\"])\n",
    "#     plain_model.blocks._modules[str(m)].attn.value.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.self.value.bias\"])\n",
    "#     plain_model.blocks._modules[str(m)].attn.proj.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.dense.weight\"]) # .t()\n",
    "#     plain_model.blocks._modules[str(m)].attn.proj.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.dense.bias\"])\n",
    "#     plain_model.blocks._modules[str(m)].ln1.weight = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.LayerNorm.weight\"])\n",
    "#     plain_model.blocks._modules[str(m)].ln1.bias = torch.nn.Parameter(weights[layer+str(m)+\".attention.output.LayerNorm.bias\"])\n",
    "#     plain_model.blocks._modules[str(m)].ff._modules['0'].weight = torch.nn.Parameter(weights[layer+str(m)+\".intermediate.dense.weight\"]) # .t()\n",
    "#     plain_model.blocks._modules[str(m)].ff._modules['0'].bias = torch.nn.Parameter(weights[layer+str(m)+\".intermediate.dense.bias\"])\n",
    "#     plain_model.blocks._modules[str(m)].ff._modules['2'].weight = torch.nn.Parameter(weights[layer+str(m)+\".output.dense.weight\"]) # .t()\n",
    "#     plain_model.blocks._modules[str(m)].ff._modules['2'].bias = torch.nn.Parameter(weights[layer+str(m)+\".output.dense.bias\"])\n",
    "#     plain_model.blocks._modules[str(m)].ln2.weight = torch.nn.Parameter(weights[layer+str(m)+\".output.LayerNorm.weight\"])\n",
    "#     plain_model.blocks._modules[str(m)].ln2.bias = torch.nn.Parameter(weights[layer+str(m)+\".output.LayerNorm.bias\"])\n",
    "# plain_model.pooler.weight = torch.nn.Parameter(weights[\"bert.pooler.dense.weight\"]) # .t()\n",
    "# plain_model.pooler.bias = torch.nn.Parameter(weights[\"bert.pooler.dense.bias\"])\n",
    "# plain_model.classifier.weight = torch.nn.Parameter(weights[\"classifier.weight\"]) # .t()\n",
    "# plain_model.classifier.bias = torch.nn.Parameter(weights[\"classifier.bias\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# Classify the encrypted data\n",
    "print(\"forward\")\n",
    "x = {}\n",
    "x['input_ids'] = data[0][\"input_ids\"]\n",
    "x['token_type_ids'] = data[0][\"token_type_ids\"]\n",
    "# x['input_ids'] = torch.tensor([1])\n",
    "# x['token_type_ids'] = torch.tensor([0, 1, 0, 1])\n",
    "word_embedding = plain_model.word_embed(x[\"input_ids\"])\n",
    "pos_embedding = plain_model.pos_embed[:, :x[\"input_ids\"].size()[1], :]\n",
    "type_embedding = plain_model.type_embed(x[\"token_type_ids\"])\n",
    "x = word_embedding + pos_embedding + type_embedding\n",
    "x = plain_model.ln(x)\n",
    "# v = '0'\n",
    "# x = plain_model.blocks._modules[v].attn(x)\n",
    "x = plain_model.blocks._modules['0'](x)\n",
    "x = plain_model.blocks._modules['1'](x)\n",
    "x = plain_model.blocks._modules['2'](x)\n",
    "x = plain_model.blocks._modules['3'](x)\n",
    "x = plain_model.blocks._modules['4'](x)\n",
    "x = plain_model.blocks._modules['5'](x)\n",
    "x = plain_model.blocks._modules['6'](x)\n",
    "x = plain_model.blocks._modules['7'](x)\n",
    "x = plain_model.blocks._modules['8'](x)\n",
    "x = plain_model.blocks._modules['9'](x)\n",
    "x = plain_model.blocks._modules['10'](x)\n",
    "x = plain_model.blocks._modules['11'](x)\n",
    "x = plain_model.pooler(x[:, 0, :])\n",
    "x = x.tanh()\n",
    "x = plain_model.classifier(x)\n",
    "\n",
    "# x = plain_model(x)\n",
    "print('output')\n",
    "# Compute the accuracy\n",
    "output = x\n",
    "print(f\"{output.shape=}\")\n",
    "print(f\"{output=}\")\n",
    "print(f\"{output.max()} {output.min()}\")\n",
    "print(f\"{output.mean()} {output.var()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for label in range(10):\n",
    "    x = {}\n",
    "    x['input_ids'] = data[label][\"input_ids\"]\n",
    "    x['token_type_ids'] = data[label][\"token_type_ids\"]\n",
    "    outputs = plain_model(x)\n",
    "    print(outputs)\n",
    "    count += targets[label] == outputs.argmax()\n",
    "    total += 1\n",
    "count / total"
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "390894444956881"
  },
  "disseminate_notebook_info": {
   "bento_version": "20190826-030256",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "error": "The file located at '/data/users/shobha/fbsource/fbcode/bento/kernels/local/cryptenk/TARGETS' could not be found."
   },
   "no_uii": true,
   "notebook_number": "139932",
   "others_can_edit": true,
   "reviewers": "",
   "revision_id": "375902760006757",
   "tags": "",
   "tasks": "",
   "title": "Tutorial 4 -- Classification with Encrypted Neural Networks"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
